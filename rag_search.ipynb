{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from langchain_core.tools import tool\n",
    "import pandas as pd\n",
    "import re\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_open_ai_client():\n",
    "    return openai.Client()\n",
    "\n",
    "def get_vector_chunks(open_ai_client: openai.Client) -> list:\n",
    "    \"\"\"Builds a vector store from the document.\"\"\"\n",
    "    # load text data \n",
    "    document = open('./knowledge-base/swiss_faq.md', 'r')\n",
    "\n",
    "    # Split into text chunks\n",
    "    content = document.read()\n",
    "    docs = [{\"page_content\": txt} for txt in re.split(r\"(?=\\n##)\", content)]\n",
    "\n",
    "    # Create embeddings for each chunk\n",
    "    embeddings = open_ai_client.embeddings.create(\n",
    "        model = \"text-embedding-3-small\", \n",
    "        input = [ doc['page_content'] for doc in docs ]\n",
    "    )\n",
    "\n",
    "    return (docs, [ emb.embedding for emb in embeddings.data ])\n",
    "\n",
    "def get_relevant_docs(open_ai_client, vector_chunks, query, docs):\n",
    "    \"\"\"Queries the vector store for the top k most similar documents.\"\"\" \n",
    "    # Create embedding for the query\n",
    "    embed = open_ai_client.embeddings.create(\n",
    "        model=\"text-embedding-3-small\", input=[query]\n",
    "    )\n",
    "    \n",
    "    # Calculate similarity scores\n",
    "    scores = np.array(embed.data[0].embedding) @ np.array(vector_chunks).T\n",
    "    \n",
    "    # Get top k chunks\n",
    "    k = 5\n",
    "    top_k_idx = np.argpartition(scores, -k)[-k:]\n",
    "    top_k_idx_sorted = top_k_idx[np.argsort(-scores[top_k_idx])]\n",
    "    \n",
    "    return [\n",
    "        {**docs[idx], \"similarity\": scores[idx]} for idx in top_k_idx_sorted\n",
    "    ]\n",
    "\n",
    "def answer_query(query: str, filtered_relevant_docs: list) -> str:\n",
    "    \"\"\"Answer a query about the company's policies.\"\"\"\n",
    "    if (not filtered_relevant_docs) or (len(filtered_relevant_docs) == 0):\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"content\": \"No relevant information found.\" \n",
    "        }\n",
    "    \n",
    "    # Combine the content of the top documents\n",
    "    content = \"\\n\\n\".join([doc for doc in filtered_relevant_docs])\n",
    "    \n",
    "    response = openai.Client().chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Context: {content} \\n\\n Question: {query}\"}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"success\": True,\n",
    "        \"content\": response.choices[0].message.content.strip()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "import json\n",
    "\n",
    "def perform_web_search(query):\n",
    "    tool = TavilySearch(\n",
    "        max_results=5,\n",
    "        topic=\"general\",\n",
    "        include_answer=True,\n",
    "    )\n",
    "\n",
    "    model_generated_tool_call = {\n",
    "        \"args\": {\"query\": query},\n",
    "        \"id\": \"1\",\n",
    "        \"name\": \"tavily\",\n",
    "        \"type\": \"tool_call\",\n",
    "    }\n",
    "    tool_msg = tool.invoke(model_generated_tool_call)\n",
    "\n",
    "    search_result = json.loads(tool_msg.content)\n",
    "    return search_result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_ai_client = get_open_ai_client()\n",
    "\n",
    "docs, vector_chunks = get_vector_chunks(open_ai_client)\n",
    "\n",
    "# query = \"How to make a Italian Pizza?\"\n",
    "query = \"Should I reconfirm my flight?\"\n",
    "relevant_docs = get_relevant_docs(open_ai_client, vector_chunks, query, docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(0.43296246682792716), np.float64(0.399930448665162), np.float64(0.35440156372272646), np.float64(0.335730996429779), np.float64(0.32014820404430455)]\n",
      "{'success': True, 'content': 'No, reconfirmation of SWISS flights is not required.'}\n"
     ]
    }
   ],
   "source": [
    "score_threshold = 0.30\n",
    "similarity_scores = [doc[\"similarity\"] for doc in relevant_docs]\n",
    "print(similarity_scores)\n",
    "filtered_relevant_docs = [\n",
    "    doc[\"page_content\"] for doc in relevant_docs if doc[\"similarity\"] > score_threshold\n",
    "]\n",
    "\n",
    "if(len(filtered_relevant_docs) > 0):\n",
    "    # print(\"\\n\\n\".join(filtered_relevant_docs))\n",
    "    result = answer_query(query, filtered_relevant_docs)\n",
    "    print(result)\n",
    "else:\n",
    "    print(\"No relevant documents found with sufficient similarity score.\")\n",
    "    print(\"Performing a Web Search\")\n",
    "    search_results = perform_web_search(query)\n",
    "    print(search_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saurav-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
